{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b9512c7",
   "metadata": {},
   "source": [
    "# 02 – Data Cleaning & Quality Assurance  \n",
    "### Smart City Energy Dataset (Asian Grid Standards)\n",
    "\n",
    "This notebook continues from the data import step and performs a **full cleaning pipeline** to prepare the Smart City dataset for analytics and ML workflows.\n",
    "\n",
    "The objectives of this notebook:  \n",
    "- Assess data quality  \n",
    "- Clean invalid country names  \n",
    "- Handle missing values  \n",
    "- Remove duplicate entries  \n",
    "- Detect voltage/current/consumption outliers  \n",
    "- Remove outlier rows  \n",
    "- Produce a fully clean dataset: `df_final`  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3451160",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== DATA QUALITY CHECK ===\")\n",
    "df.info()\n",
    "\n",
    "print(\"\\nMissing values:\")\n",
    "missing = df.isnull().sum()\n",
    "print(missing[missing > 0])\n",
    "\n",
    "missing_percent = (missing/len(df))*100\n",
    "print(\"\\nMissing %:\")\n",
    "print(missing_percent[missing_percent > 0])\n",
    "\n",
    "empty_cols = missing_percent[missing_percent == 100].index.tolist()\n",
    "print(\"\\nEmpty columns:\", empty_cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ac9992",
   "metadata": {},
   "source": [
    "## 1. Data Quality Assessment  \n",
    "This step performs an initial scan of the dataset including:\n",
    "\n",
    "- Data structure (`df.info()`)\n",
    "- Missing values count and percentages\n",
    "- Detection of completely empty columns  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce10587a",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_countries = ['SolarPark','Substation','Site','Industrial','LoadHub','Center']\n",
    "print(\"\\nRows before:\", len(df))\n",
    "df_cleaned = df[~df['Country'].isin(non_countries)].copy()\n",
    "print(\"Rows after:\", len(df_cleaned))\n",
    "print(\"\\nRemaining countries:\")\n",
    "print(df_cleaned['Country'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7665e3a4",
   "metadata": {},
   "source": [
    "## 2. Cleaning the Country Column  \n",
    "The dataset contains facility names mistakenly stored in the `Country` column.  \n",
    "This step removes non-country labels:\n",
    "\n",
    "- SolarPark  \n",
    "- Substation  \n",
    "- Site  \n",
    "- Industrial  \n",
    "- LoadHub  \n",
    "- Center  \n",
    "\n",
    "The goal is to keep only valid Asian countries.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd069f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = df_cleaned.select_dtypes(include='number').columns\n",
    "for col in numeric_cols:\n",
    "    if df_cleaned[col].isnull().sum() > 0:\n",
    "        med = df_cleaned[col].median()\n",
    "        df_cleaned[col].fillna(med, inplace=True)\n",
    "        print(f\"Filled missing in {col} with median {med:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22dcb0aa",
   "metadata": {},
   "source": [
    "## 3. Missing Value Treatment (Median Imputation)  \n",
    "Missing values in numeric columns are filled using the **median**, which:\n",
    "\n",
    "- Is robust against outliers  \n",
    "- Preserves distribution shape  \n",
    "- Avoids skew caused by extreme values  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fa1e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dups = df_cleaned.duplicated().sum()\n",
    "print(\"Duplicates:\", dups)\n",
    "df_cleaned = df_cleaned.drop_duplicates()\n",
    "print(\"New shape:\", df_cleaned.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64240ed5",
   "metadata": {},
   "source": [
    "## 4. Duplicate Row Removal  \n",
    "Duplicate rows distort statistical analysis and time-series patterns.  \n",
    "This step:\n",
    "\n",
    "- Detects duplicate rows  \n",
    "- Removes them  \n",
    "- Confirms new dataset size  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d455a289",
   "metadata": {},
   "outputs": [],
   "source": [
    "ASIA_VOLT = {'min':90,'max':250}\n",
    "\n",
    "def detect_voltage_outliers_asia(data, col='Voltage (V)'):\n",
    "    low, high = ASIA_VOLT['min'], ASIA_VOLT['max']\n",
    "    out = data[(data[col] < low) | (data[col] > high)]\n",
    "    print(f\"Voltage outliers: {len(out)}\")\n",
    "    return out\n",
    "\n",
    "def detect_outliers_iqr(data, col):\n",
    "    Q1 = data[col].quantile(0.25)\n",
    "    Q3 = data[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    low = Q1 - 1.5 * IQR\n",
    "    high = Q3 + 1.5 * IQR\n",
    "    out = data[(data[col] < low) | (data[col] > high)]\n",
    "    print(f\"{col} outliers: {len(out)}\")\n",
    "    return out, low, high\n",
    "\n",
    "voltage_out = detect_voltage_outliers_asia(df_cleaned)\n",
    "current_out, _, _ = detect_outliers_iqr(df_cleaned, 'Current (A)')\n",
    "power_out, _, _ = detect_outliers_iqr(df_cleaned, 'Power Consumption')\n",
    "\n",
    "all_out_idx = set(voltage_out.index) | set(current_out.index) | set(power_out.index)\n",
    "print(\"Total unique outlier rows:\", len(all_out_idx))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40b0a52",
   "metadata": {},
   "source": [
    "## 5. Outlier Detection  \n",
    "Outliers are detected for:  \n",
    "\n",
    "### Voltage (V) — Asian Grid Standard  \n",
    "Valid range: **90V – 250V**\n",
    "\n",
    "### Current (A) — IQR Method  \n",
    "### Power Consumption — IQR Method  \n",
    "\n",
    "We identify rows with extreme or unrealistic values.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f5794d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_cleaned.drop(index=list(all_out_idx))\n",
    "print(\"Final shape after removing outliers:\", df_final.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160fc3f2",
   "metadata": {},
   "source": [
    "### Cleaning complete. Dataset stored in `df_final`. Ready for EDA."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
